{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pybtex.database import BibliographyData, Entry\n",
    "import re\n",
    "# from utils.helper import search_studies, assert_list, get_citation, fetch_data\n",
    "from utils.helper import *\n",
    "\n",
    "class NOAAStudies:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the NOAAStudies class with base URL and dictionaries to hold studies and data table indices.\n",
    "\n",
    "\n",
    "        The search parameters are designed to be flexible and can vary for different searches using the same object.\n",
    "        Instead of overwriting the initialized default parameters, each search maintains its own set of parameters, \n",
    "        allowing for independent configurations across multiple searches.\n",
    "        \"\"\"\n",
    "        self.BASE_URL = \"https://www.ncei.noaa.gov/access/paleo-search/study/search.json\"\n",
    "        self.studies = {}\n",
    "        self.data_table_index = {}\n",
    "\n",
    "    def search_studies(self, xml_id=None, noaa_id=None, data_publisher=\"NOAA\", data_type_id = None, keywords = None, investigators=None, \n",
    "                       max_lat=None, min_lat=None, max_lon=None, min_lon=None, location = None, publication = None, search_text = None, \n",
    "                       earliest_year = None, latest_year = None, cv_whats = None, recent = False):\n",
    "        \"\"\"\n",
    "        Search for NOAA studies using specific search parameters.\n",
    "        \n",
    "        Parameters:\n",
    "            xml_id (str): XML ID of the study. (Primary)\n",
    "            noaa_id (str): NOAA study ID. (Primary)\n",
    "            data_publisher (str): Data publisher's name. Default: NOAA \n",
    "            data_type_id (str): Data Type specific Studies.\n",
    "            keywords (str): Keywords to search for.  \n",
    "            investigators (str): Name(s) of investigators.\n",
    "            min_lat/max_lat (float): Latitude range for location-based search.\n",
    "            min_lat/max_lat (float): Longitude range for location-based search.\n",
    "            location (str): Location description.\n",
    "            species (str): FOUR letter code species code\n",
    "            publication (str): Specific publication.\n",
    "            search_text (str): Publication / studyNotes / String based search.\n",
    "           \n",
    "        \"\"\"\n",
    "        if noaa_id:\n",
    "            params = {'NOAAStudyId': noaa_id}\n",
    "        elif xml_id:\n",
    "            params = {'xmlId': xml_id}\n",
    "        else:\n",
    "            params = {\n",
    "            'dataPublisher' : data_publisher,\n",
    "            'dataTypeId' : data_type_id,\n",
    "            'keywords' : keywords, \n",
    "            'investigators' : investigators,\n",
    "            'minLat' : min_lat,\n",
    "            'maxLat' : max_lat,\n",
    "            'minLon' : min_lon,\n",
    "            'maxLon' : max_lon,\n",
    "            'locations' : location,\n",
    "            'searchText' : publication, \n",
    "            'searchText' : search_text,\n",
    "            'cvWhats': cv_whats,\n",
    "            'earliestYear' : earliest_year,\n",
    "            'latestYear': latest_year, \n",
    "            'recent' : recent,\n",
    "        }\n",
    "        # Filtering out None values\n",
    "        # params = {k: v for k, v in params.items() if v}\n",
    "        # response = requests.get(self.BASE_URL, params=params)\n",
    "        # if response.status_code == 200:\n",
    "        #     self.response_parser(response.json())\n",
    "        # else:\n",
    "        #     print(f\"Error fetching studies: {response.status_code}\")\n",
    "\n",
    "        self.response_parser(search_studies(params))\n",
    "\n",
    "    def response_parser(self, data):\n",
    "        \"\"\"\n",
    "        Parse the JSON response from NOAA and populate the studies dictionary.\n",
    "        \n",
    "        Parameters:\n",
    "            data (dict): The JSON data returned from a search query.\n",
    "        \"\"\"\n",
    "        for study in data.get('study', []):\n",
    "            noaa_study_id = study.get('NOAAStudyId')\n",
    "            xml_study_id = study.get('xmlId')\n",
    "            self.studies[noaa_study_id] = {\n",
    "                'base_meta': self.load_base_meta(study),\n",
    "                'investigators': self.load_investigators(study),\n",
    "                'publications': self.load_publications(study),\n",
    "                'sites': self.load_sites(study, noaa_study_id),\n",
    "                # 'number of sites': len(sites)\n",
    "                'pageUrl' : study.get('onlineResourceLink', np.nan)\n",
    "            }\n",
    "\n",
    "    def load_base_meta(self, study):\n",
    "        \"\"\"\n",
    "        Load base metadata for a study.\n",
    "        \n",
    "        Parameters:\n",
    "            study (dict): Part of the JSON data pertaining to a single study.\n",
    "        \"\"\"\n",
    "        fields = ['NOAAStudyId', 'studyName', 'dataType', 'earliestYearBP', 'mostRecentYearBP',\n",
    "                  'earliestYearCE', 'mostRecentYearCE', 'studyNotes', 'scienceKeywords']\n",
    "        return {field: study.get(field, np.nan) for field in fields}\n",
    "\n",
    "    def load_investigators(self, study):\n",
    "        \"\"\"\n",
    "        Extract investigator details from the study data.\n",
    "        \n",
    "        Parameters:\n",
    "            study (dict): Part of the JSON data pertaining to a single study.\n",
    "        \"\"\"\n",
    "        investigators = study.get(\"investigatorDetails\", [])\n",
    "        if investigators:\n",
    "            return \", \".join([f\"{i.get('firstName', 'N/A')} {i.get('lastName', 'N/A')}\" for i in investigators])\n",
    "        return np.nan\n",
    "\n",
    "    def load_publications(self, study):\n",
    "        \"\"\"\n",
    "        Extract and format publication data from the study as a dictionary.\n",
    "\n",
    "        Parameters:\n",
    "            study (dict): Part of the JSON data pertaining to a single study.\n",
    "            study_id (str): The unique identifier for the NOAA study.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of dictionaries representing publication details.\n",
    "        \"\"\"\n",
    "        publications = []\n",
    "        for pub in study.get('publication', []):\n",
    "            author_info = pub.get('author', {})\n",
    "            identifier_info = pub.get('identifier', {})\n",
    "\n",
    "            # Extract fields for the publication dictionary\n",
    "            publication_data = {\n",
    "                'NOAAStudyId': study.get('NOAAStudyId'),\n",
    "                'author': author_info.get('name', 'Unknown Author'),\n",
    "                'title': pub.get('title', 'Unknown Title'),\n",
    "                'journal': pub.get('journal', 'Unknown Journal'),\n",
    "                'year': str(pub.get('pubYear', 'Unknown Year')),\n",
    "                'volume': pub.get('volume', np.nan),\n",
    "                'number': pub.get('issue', np.nan),\n",
    "                'pages': pub.get('pages', np.nan),\n",
    "                'type': pub.get('type', np.nan),\n",
    "                'doi': identifier_info.get('id', np.nan) if identifier_info else np.nan,\n",
    "                'url': identifier_info.get('url', np.nan) if identifier_info else np.nan\n",
    "            }\n",
    "\n",
    "            # Add the publication dictionary to the list\n",
    "            publications.append(publication_data)\n",
    "        \n",
    "        return publications\n",
    "\n",
    "    def load_sites(self, study, study_id):\n",
    "        \"\"\"\n",
    "        Load and format site data associated with the study.\n",
    "        \n",
    "        Parameters:\n",
    "            study (dict): Part of the JSON data pertaining to a single study.\n",
    "            study_id (str): The unique identifier of the study for reference.\n",
    "        \"\"\"        \n",
    "        return {\n",
    "            site.get('NOAASiteId', np.nan): {\n",
    "                'siteName': site.get('siteName', np.nan),\n",
    "                'locationName': site.get('locationName', np.nan),\n",
    "                'lat': site.get('geo', {}).get('geometry', {}).get('coordinates', [None, None])[0],\n",
    "                'lon': site.get('geo', {}).get('geometry', {}).get('coordinates', [None, None])[1],\n",
    "                'paleoData': self.load_paleo_data(site.get('paleoData', []), study_id, site.get('NOAASiteId'))\n",
    "            }\n",
    "            for site in study.get('site', [])\n",
    "        }\n",
    "\n",
    "    def load_paleo_data(self, paleoData, study_id, site_id):\n",
    "        \"\"\"\n",
    "        Extract and format paleo data associated with a site.\n",
    "        \n",
    "        Parameters:\n",
    "            paleoData (list): List of paleo data from the site.\n",
    "            study_id (str): The unique identifier of the study.\n",
    "            site_id (str): The unique identifier of the site.\n",
    "        \"\"\"\n",
    "        paleo_dict = {}\n",
    "        for paleo in paleoData:\n",
    "            # Safe access to 'dataFile' list\n",
    "            data_files = paleo.get('dataFile', [])\n",
    "            file_url = data_files[0].get('fileUrl', np.nan) if data_files else np.nan\n",
    "            variables = []\n",
    "            if data_files:  # Check if 'dataFile' is not empty\n",
    "                variables = [var.get('cvShortName', np.nan) for var in data_files[0].get('variables', [])]\n",
    "            data_table_id = paleo.get('NOAADataTableId', np.nan)\n",
    "            paleo_details = {\n",
    "                'NOAADataTableId': data_table_id,\n",
    "                'dataTableName': paleo.get('dataTableName', np.nan),\n",
    "                'timeUnit': paleo.get('timeUnit', np.nan),\n",
    "                'fileUrl': file_url,\n",
    "                'variables': variables\n",
    "            }\n",
    "            paleo_dict[data_table_id] = paleo_details\n",
    "\n",
    "            self.data_table_index[data_table_id] = {\n",
    "                'file_url': file_url,\n",
    "                'study_id': study_id,\n",
    "                'site_id': site_id\n",
    "            }\n",
    "        return paleo_dict\n",
    "\n",
    "        \n",
    "    def get_response(self):\n",
    "        \"\"\"\n",
    "        Compile and return a DataFrame of all loaded studies along with their detailed metadata and linked information.\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame: A DataFrame representing the consolidated data of all studies, including metadata, investigators,\n",
    "                       publications, and site details.\n",
    "        \"\"\"\n",
    "        data = [{\n",
    "            **study['base_meta'],\n",
    "            'Investigators': study['investigators'],\n",
    "            'publications': study['publications'],\n",
    "            'sites': study['sites']\n",
    "        } for study in self.studies.values()]\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "    def get_publications(self, study_ids, output_format=\"dataframe\"):\n",
    "        \"\"\"\n",
    "        Return publications for one or more study IDs in the specified format.\n",
    "\n",
    "        Parameters:\n",
    "            study_ids (list or str): Single or list of NOAAStudyIds.\n",
    "            output_format (str): The desired output format. Options:\n",
    "                - \"dataframe\": Returns a pandas DataFrame of publication details.\n",
    "                - \"bibtex\": Returns a pybtex.database.BibliographyData object.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame or pybtex.database.BibliographyData: Publications data in the chosen format.\n",
    "        \"\"\"\n",
    "        study_ids = assert_list(study_ids)  # Ensure study_ids is a list\n",
    "        \n",
    "        if output_format == \"dataframe\":            \n",
    "            dfs = []\n",
    "            for study_id in study_ids:\n",
    "                if study_id in self.studies:\n",
    "                    publications = self.studies[study_id].get('publications', [])\n",
    "                    df = pd.DataFrame(publications)\n",
    "                    # df.set_index('NOAAStudyId', inplace=True)  # Set NOAAStudyId as the index\n",
    "                    dfs.append(df)\n",
    "                else:\n",
    "                    print(f\"Study ID {study_id} not found.\")\n",
    "            display(pd.concat(dfs))\n",
    "            return pd.concat(dfs) if dfs else pd.DataFrame()\n",
    "\n",
    "        elif output_format == \"bibtex\":            \n",
    "            bib_entries = {}\n",
    "            for study_id in study_ids:\n",
    "                if study_id in self.studies:\n",
    "                    publications = self.studies[study_id].get('publications', [])\n",
    "                    for pub in publications:\n",
    "                        fields = {k: v for k, v in pub.items() if k not in ['NOAAStudyId'] and v}\n",
    "                        entry = Entry('article', fields=fields)\n",
    "                        citation_key = get_citation(pub)\n",
    "                        bib_entries[citation_key] = entry\n",
    "                else:\n",
    "                    print(f\"Study ID {study_id} not found.\")\n",
    "            \n",
    "            return BibliographyData(entries=bib_entries)\n",
    "\n",
    "        else:\n",
    "            print(\"Invalid output_format. Choose 'dataframe' or 'bibtex'.\")\n",
    "\n",
    "    def get_sites(self, study_ids):\n",
    "        \"\"\"\n",
    "        Return a DataFrame of sites for one or more study IDs.\n",
    "\n",
    "        Parameters:\n",
    "            study_ids (list or str): Single or list of NOAAStudyIds.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Sites DataFrame.\n",
    "        \"\"\"\n",
    "        study_ids = assert_list(study_ids)  # Convert to list if single ID\n",
    "        \n",
    "        dfs = []\n",
    "        for study_id in study_ids:\n",
    "            if study_id not in self.studies:\n",
    "                print(f\"Study ID {study_id} not found.\")\n",
    "                continue\n",
    "            \n",
    "            sites_data = self.studies[study_id].get('sites', {})\n",
    "            sites_list = []\n",
    "            for site_id, site_info in sites_data.items():\n",
    "                site_info['NOAASiteId'] = site_id\n",
    "                paleo_list = site_info.pop('paleoData', {})\n",
    "                for paleo_id, paleo_info in paleo_list.items():\n",
    "                    record = {**site_info, **paleo_info, 'NOAADataTableId': paleo_id, 'NOAAStudyId': study_id}\n",
    "                    sites_list.append(record)\n",
    "\n",
    "            if sites_list:\n",
    "                df = pd.DataFrame(sites_list)\n",
    "                dfs.append(df)\n",
    "                # print(dfs)\n",
    "        \n",
    "        result = pd.concat(dfs) if dfs else pd.DataFrame()\n",
    "        result.set_index('NOAAStudyId', inplace=True)  # Set NOAAStudyId as the index\n",
    "        return result\n",
    "\n",
    "    def get_data(self, dataTableIDs=None, file_urls=None):\n",
    "        \"\"\"\n",
    "        Fetch and return the data for one or more dataTableIDs or file URLs.\n",
    "\n",
    "        Parameters:\n",
    "            dataTableIDs (list or str): Single or list of NOAADataTableIds.\n",
    "            file_urls (list or str): Single or list of file URLs.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Combined DataFrame of all fetched data.\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\" \n",
    "        @TODO: \n",
    "            Add attributes to each data frame\n",
    "             \n",
    "        \"\"\"\n",
    "        if dataTableIDs:\n",
    "            dataTableIDs = assert_list(dataTableIDs)\n",
    "            dfs = []\n",
    "            for dataTableID in dataTableIDs:\n",
    "                file_url = self.data_table_index.get(dataTableID, {}).get('file_url')\n",
    "                if not file_url:\n",
    "                    print(f\"Data Table ID {dataTableID} not found or no associated file URL.\")\n",
    "                    continue\n",
    "                print(f\"File URL {type(file_url)}\")\n",
    "                df = fetch_data(file_url)\n",
    "\n",
    "            study_id = self.data_table_index[dataTableID].get('study_id')\n",
    "            site_id = self.data_table_index[dataTableID].get('site_id')\n",
    "            study_data = self.studies.get(study_id, {})\n",
    "            \n",
    "            # Attach attributes to DataFrame\n",
    "            df.attrs['NOAAStudyId'] = study_id\n",
    "            df.attrs['Publication'] = study_data.get('publications', 'N/A')\n",
    "            site_data = study_data.get('sites', {}).get(site_id, {})\n",
    "            df.attrs['Lat'] = site_data.get('lat', 'N/A')\n",
    "            df.attrs['Lon'] = site_data.get('lon', 'N/A')\n",
    "            df.attrs['fileURL'] = file_url\n",
    "\n",
    "            dfs.append(df)\n",
    "            return dfs\n",
    "        \n",
    "        if file_urls:\n",
    "            file_urls = assert_list(file_urls)  # Convert to list if single URL\n",
    "            dfs = [fetch_data(file_url) for file_url in file_urls]\n",
    "            return dfs\n",
    "\n",
    "        print(\"No dataTableID or file URL provided.\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = {\"study\": [\n",
    "    {\n",
    "      \"xmlId\": \"16017\",\n",
    "      \"NOAAStudyId\": \"18315\",\n",
    "      \"studyName\": \"Makassar Strait - Single specimens of P. obliquiloculata d18O and d13C from 704-1851 AD\",\n",
    "      \"dataPublisher\": \"NOAA\",\n",
    "      \"dataType\": \"PALEOCEANOGRAPHY\",\n",
    "      \"investigatorDetails\": [\n",
    "        {\n",
    "          \"firstName\": \"Deborah\",\n",
    "          \"lastName\": \"Khider\",\n",
    "          \"initials\": \"D.\",\n",
    "          \"orcId\": \"0000-0001-7501-8430\"\n",
    "        },\n",
    "        {\n",
    "          \"firstName\": \"Lowell\",\n",
    "          \"lastName\": \"Stott\",\n",
    "          \"initials\": \"L.D.\",\n",
    "          \"orcId\": \"0000-0002-2025-0731\"\n",
    "        },\n",
    "        {\n",
    "          \"firstName\": \"Julien\",\n",
    "          \"lastName\": \"Emile-Geay\",\n",
    "          \"initials\": \"J.\",\n",
    "          \"orcId\": \"0000-0001-5920-4751\"\n",
    "        },\n",
    "        {\n",
    "          \"firstName\": \"Robert\",\n",
    "          \"lastName\": \"Thunell\",\n",
    "          \"initials\": \"R.C.\",\n",
    "          \"orcId\": \"0000-0001-7052-1707\"\n",
    "        },\n",
    "        {\n",
    "          \"firstName\": \"Doug\",\n",
    "          \"lastName\": \"Hammond\",\n",
    "          \"initials\": \"D.E.\",\n",
    "          \"orcId\": None\n",
    "        }\n",
    "      ],\n",
    "      \"studyNotes\": \"This dataset contains the d18O, d13C, and weights of single specimens of P. obliquiloculata used in the reconstruction of ENSO variability over the past 2,000 years.\",\n",
    "      \"onlineResourceLink\": \"https://www.ncei.noaa.gov/access/paleo-search/study/18315\",\n",
    "      \"scienceKeywords\": [\n",
    "        \"ENSO\",\n",
    "        \"Medieval Climate Anomaly (MCA)\",\n",
    "        \"Little Ice Age (LIA)\"\n",
    "      ],\n",
    "      \"earliestYearBP\": 1246,\n",
    "      \"mostRecentYearBP\": 99,\n",
    "      \"earliestYearCE\": 704,\n",
    "      \"mostRecentYearCE\": 1851,\n",
    "      \"publication\": [\n",
    "        {\n",
    "          \"author\": {\n",
    "            \"name\": \"Khider, D\"\n",
    "          },\n",
    "          \"pubYear\": 2011,\n",
    "          \"title\": \"Assessing El Nino Southern Oscillation variability during the past millennium\",\n",
    "          \"journal\": \"Paleoceanography\",\n",
    "          \"volume\": \"26\",\n",
    "          \"edition\": None,\n",
    "          \"issue\": None,\n",
    "          \"pages\": None,\n",
    "          \"reportNumber\": \"PA3222\",\n",
    "          \"citation\": \"Khider, D., L. Stott, J. Emile-Geay, R. Thunell, and D.E. Hammond. 2011. Assessing El Nino Southern Oscillation variability during the past millennium. Paleoceanography, 26, PA3222. doi: 10.1029/2011PA002139\",\n",
    "          \"type\": \"publication\",\n",
    "          \"identifier\": {\n",
    "            \"type\": \"doi\",\n",
    "            \"id\": \"10.1029/2011PA002139\",\n",
    "            \"url\": \"http://dx.doi.org/10.1029/2011PA002139\"\n",
    "          },\n",
    "          \"abstract\": \"We present a reconstruction of El Nino Southern Oscillation (ENSO) variability spanning the Medieval Climate Anomaly (MCA, A.D. 800-1300) and the Little Ice Age (LIA, A.D. 1500-1850). Changes in ENSO are estimated by comparing the spread and symmetry of d18O values of individual speciments of the thermocline-dwelling foraminifer Pulleniatina obliquiloculata extracted from discrete time horizons of a sediment core collected in the Sulawesi Sea, at the edge of the western tropical Pacific warm pool. The spread of individual d18O values is interpreted to be a measure of the strength of both phases of ENSO while the symmetry of the d18O distributions is used to evaluate the relative strength/frequency of El Nino and La Nina events. In contrast to previous studies, we use robust and resistant statistics to quantify the spread and symmetry of the d18O distributions; an approach motivated by the relatively small sample size and the presence of outliers. Furthermore, we use a pseudo-proxy to investigate the effects of the different paleo-environmental factors on the statistics of the d18O distributions, which could bias the paleo-ENSO reconstruction. We find no systematic difference in the magnitude/strength of ENSO during the Nothern Hemisphere MCA or LIA. However, our results suggest that ENSO during the MCA was kewed toward stronger/more frequent La Nina than El Nino, an observation consistent with the medieval megadroughts documented from sites in western North America.\",\n",
    "          \"pubRank\": \"1\"\n",
    "        }\n",
    "      ],\n",
    "      \"site\": [\n",
    "        {\n",
    "          \"NOAASiteId\": \"53040\",\n",
    "          \"siteName\": \"MD98-2177\",\n",
    "          \"locationName\": \"Ocean\\u003EPacific Ocean\\u003EWestern Pacific Ocean\",\n",
    "          \"geo\": {\n",
    "            \"geoType\": \"Feature\",\n",
    "            \"geometry\": {\n",
    "              \"type\": \"POINT\",\n",
    "              \"coordinates\": [\n",
    "                \"1.4033\",\n",
    "                \"119.078\"\n",
    "              ]\n",
    "            },\n",
    "          },\n",
    "          \"paleoData\": [\n",
    "            {\n",
    "              \"dataTableName\": \"MD98-2177 isotopes Khider11\",\n",
    "              \"NOAADataTableId\": \"28674\",\n",
    "              \"timeUnit\": \"CE\",\n",
    "              \"dataFile\": [\n",
    "                {\n",
    "                  \"fileUrl\": \"https://www.ncei.noaa.gov/pub/data/paleo/contributions_by_author/khider2011/khider2011.txt\",\n",
    "                  \"variables\": [\n",
    "                    {\n",
    "                      \"cvShortName\": None\n",
    "                    },\n",
    "                    {\n",
    "                      \"cvShortName\": None\n",
    "                    },\n",
    "                    {\n",
    "                      \"cvShortName\": None\n",
    "                    },\n",
    "                    {\n",
    "                      \"cvShortName\": None\n",
    "                    },\n",
    "                    {\n",
    "                      \"cvShortName\": None\n",
    "                    },\n",
    "                    {\n",
    "                      \"cvShortName\": None\n",
    "                    },\n",
    "                    {\n",
    "                      \"cvShortName\": None\n",
    "                    }\n",
    "                  ],\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "    }\n",
    "    ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "noaaStudies = NOAAStudies() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "noaaStudies.response_parser(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOAAStudyId</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>journal</th>\n",
       "      <th>year</th>\n",
       "      <th>volume</th>\n",
       "      <th>number</th>\n",
       "      <th>pages</th>\n",
       "      <th>type</th>\n",
       "      <th>doi</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18315</td>\n",
       "      <td>Khider, D</td>\n",
       "      <td>Assessing El Nino Southern Oscillation variabi...</td>\n",
       "      <td>Paleoceanography</td>\n",
       "      <td>2011</td>\n",
       "      <td>26</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>publication</td>\n",
       "      <td>10.1029/2011PA002139</td>\n",
       "      <td>http://dx.doi.org/10.1029/2011PA002139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NOAAStudyId     author                                              title  \\\n",
       "0       18315  Khider, D  Assessing El Nino Southern Oscillation variabi...   \n",
       "\n",
       "            journal  year volume number pages         type  \\\n",
       "0  Paleoceanography  2011     26   None  None  publication   \n",
       "\n",
       "                    doi                                     url  \n",
       "0  10.1029/2011PA002139  http://dx.doi.org/10.1029/2011PA002139  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = noaaStudies.get_publications('18315')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File URL <class 'str'>\n",
      "https://www.ncei.noaa.gov/pub/data/paleo/contributions_by_author/khider2011/khider2011.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[     depth_top depth_bottom age_ADbot age_ADtop d13CcarbVPDB d18OcarbVPDB  \\\n",
       " 0            0            1      1843      1851        0.936       -2.254   \n",
       " 1            0            1      1843      1851        0.895       -2.356   \n",
       " 2            0            1      1843      1851        0.514        -2.63   \n",
       " 3            0            1      1843      1851          0.9        -2.48   \n",
       " 4            0            1      1843      1851        0.957       -2.094   \n",
       " ...        ...          ...       ...       ...          ...          ...   \n",
       " 1160        96           98       704       734        0.711       -1.719   \n",
       " 1161        96           98       704       734        0.852        -1.69   \n",
       " 1162        96           98       704       734         0.68       -2.093   \n",
       " 1163        96           98       704       734         0.69       -2.023   \n",
       " 1164        96           98       704       734        0.629       -2.361   \n",
       " \n",
       "      wgt-ind\\r  \n",
       " 0         34\\r  \n",
       " 1         37\\r  \n",
       " 2         20\\r  \n",
       " 3         25\\r  \n",
       " 4         29\\r  \n",
       " ...        ...  \n",
       " 1160      23\\r  \n",
       " 1161      23\\r  \n",
       " 1162      18\\r  \n",
       " 1163      17\\r  \n",
       " 1164      43\\r  \n",
       " \n",
       " [1165 rows x 7 columns]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noaaStudies.get_data(dataTableIDs='28674')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
